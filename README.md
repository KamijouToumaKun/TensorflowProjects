# TensorflowProjects
Some projects using Tensorflow

## 手打一些书上的代码来进行TensorFlow的学习
### fizzbuzz.py
拟合出这样的规律：对于15的倍数输出fizzbuzz，3的倍数输出fizz，5的倍数输出buzz，其他数字直接输出  
通过这个项目来初步了解TensorFlow：包括特征和label如何编码，神经网络各层之间的连接  
### circles.py
拟合出这样的规律：对于数字的十进制表示的末四位（不足4位的用0补齐）输出其中圈的个数：每有1位是0或6或9则圈数+1，每有一位是8则圈数+2  
通过这个项目来初步了解调参，例如增加神经网络的层数和神经元个数、学习率、提取特征的方式  
调参得到的对比和心得写在注释里面  
### real_sin.py
使用两层的RNN-LSTM网络预测sin x函数的取值；这是一个回归问题而不是分类问题，使用变量和搭建网络的方式也有很大区别，参见注释  
奇怪的是，训练时的loss跟预期相一致，测试时的loss却远大于预期？！  
### "LSTM RPS.py"和"LSTM sin.py"
用python2的tensorflow写的，预测sin的值和对方出剪刀石头布（分类问题）的概率  
我模拟的对方出拳的套路是，对方有5～10种套路（一种套路表示一个长为4的出拳序列），选择一种套路出完四拳后，再随机换成下一种套路  
其实，剪刀石头布应该没有这么简单；而且在通过预测让自己胜利的同时，还要考虑对方变招？这应该是一个动态的问题  
关于剪刀石头布的表示，我当初用的是1.0、2.0、3.0三个实数，没有归一化更没有表示成one-hot向量  
因为我还不知道怎么给RNN框架的每一步输入一个向量而不是一个实数。这就成了一个回归问题而不是分类问题，效果肯定会变差  
归根结底是我还不了解RNN；这个坑等以后再补了  

## mnist数据集的数字识别问题
### mnist.py
增加了l2正则项、滑动平均类用于准确率的测试、学习率的衰减  
### mnist_开头的三个文件
增加了模型的保存功能，保存在model文件夹；把程序进一步模块化、也把训练和测试分开  
 轮数 | 准确率 
 ------------- | ------------- 
 0 | 0.0704 
 5000 | 0.9686 
 10000 | 0.976 
 15000 | 0.9792 
 20000 | 0.9804 
 25000 | 0.9802 
 30000 | 0.9814 
 35000 | 0.9814 
 40000 | 0.9814 
 45000 | 0.9816 
 50000 | 0.9824 
据称最终准确率可以达到0.984  
## lenet5_开头的三个文件
使用LeNet-5模型，保存在model文件夹；图像的维度变高了，很多参数需要进行修改；加上了dropout防止过拟合
训练速度明显较慢，每训练1000轮用时40min；训练2000轮时的准确率为98.76%

## 自己创造数据集
### mydataset开头的四个文件
我是心血来潮，想试试能不能训练一个模型将它们区分开来  
于是我自己设置了10个文件夹，名字为1～10  
每个文件夹里面有两个子文件夹，名为“画”和“真人”  
找了一些二次元和三次元的图片分别放在这两个子文件夹里（数据集略）  
我知道TensorFlow有一种TFRecord文件格式  
专门用来放二进制的数据，使用流输入输出；但是我还不会用  
而且我的数据集时刻需要调整。所以我只是自己写了一个读图片的类mydataset  
作为提供图片的接口；还是用feed_dict进行数据输入  
目前的设置是，图片分成两类（分更多类的话数据更稀疏、不平衡了）  
大小归一化到28*28，变成灰度图  
结果训练出来的效果极差  
当然我现在用的是灰度图+全连接，我还可以尝试使用真彩图+CNN  
但是我认为根本在于我的数据太少了，只有上百张图片吧，于是泛化能力很差
所以还是老老实实地先用CIFAR-10之类有名的数据集做练习吧  
